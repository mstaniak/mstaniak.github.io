---
title: "Explanations of Model Predictions with live and breakDown Packages"
collection: publications
permalink: /publication/2018-12-31-explanations-of-model-predictions
excerpt: 'Paper on local interpretability of machine learning model'
date: 2018-12-31
venue: 'The R Journal'
paperurl: 'https://journal.r-project.org/archive/2018/RJ-2018-072/RJ-2018-072.pdf'
citation: 'Your Name, You. (2015). &quot;Paper Title Number 3.&quot; <i>Journal 1</i>. 1(3).'
citation: 'Mateusz Staniak and Przemysław Biecek, &quot;Explanations of Model Predictions with live and breakDown Packages&quot;, <i>The R Journal</i> (2018) 10:2, pages 395-409.'
---

**Abstract**: Complex models are commonly used in predictive modeling. In this paper we present R packages that can be used for explaining predictions from complex black box models and attributing parts of these predictions to input features. We introduce two new approaches and corresponding packages for such attribution, namely live and breakDown. We also compare their results with existing implementations of state-of-the-art solutions, namely, lime (Pedersen and Benesty, 2018) which implements Locally Interpretable Model-agnostic Explanations and iml (Molnar et al., 2018) which implements Shapley values.

[Download paper here](https://journal.r-project.org/archive/2018/RJ-2018-072/RJ-2018-072.pdf)

Recommended citation: Mateusz Staniak and Przemysław Biecek, &quot;Explanations of Model Predictions with live and breakDown Packages&quot;, <i>The R Journal</i> (2018) 10:2, pages 395-409.
